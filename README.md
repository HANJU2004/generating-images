# generating-images
测试一些图片生成模型
代码自己手写的，可能哪些细节出现了致命的问题？？然后就导致这个效果比较拉跨（我尤其指的是diffusion，剩下两个是正常水平）但当我用了带注意力的模型效果一下就好了不少，不过还是不太理想。
本来想继续改进一下，但又没空又没心情，干脆搁那里不管了，我感到孤独。。。宇宙万法的源头，我在说什么
以下有效果图。
<img width="601" alt="vaeanime1" src="https://github.com/user-attachments/assets/4cfff45f-6f80-4b93-a381-b3688562bb7c" />
<img width="480" alt="vaeanime5" src="https://github.com/user-attachments/assets/4c624889-eea6-4804-a60d-23a4c4853d33" />
![Fig<img width="600" alt="Snipaste_2024-09-14_17-26-22" src="https://github.com/user-attachments/assets/fcc8071e-dee0-4d85-8713-145f1df0809f" />
ure_1_flower](https://github.com/user-attachments/assets/39553ccf-eea0-459f-a720-8aff76c4b824)

失败案例：
<img width="480" alt="vaeanime6" src="https://github.com/user-attachments/assets/341b38b4-0847-4a6e-966a-70cda6d2830b" />
<img width="480" alt="vaeanime4" src="https://github.com/user-attachments/assets/2bfb0ffb-8d36-4a98-bed9-1bfa30b08ce2" />
